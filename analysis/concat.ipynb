{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "from nltk import stem\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "def concat(in_path):\n",
    "    allFiles = glob.glob(in_path + \"/*.txt\")\n",
    "    frame = pd.DataFrame()\n",
    "    list_ = []\n",
    "    for file_ in allFiles:\n",
    "        df_ = pd.read_table(file_,index_col=False, header=0)\n",
    "        list_.append(df_)\n",
    "    df = pd.concat(list_)\n",
    "    df.to_csv(out_path+\"articles.csv\")\n",
    "    print len(df)\n",
    "    return df  \n",
    "\n",
    "def extract_docs(df):\n",
    "    docs_csv=out_path+\"docs.csv\"\n",
    "    df=df[~df.AB.isnull()]\n",
    "    df.AB.to_csv(docs_csv, index=False)\n",
    "    print len(df)\n",
    "    with open(docs_csv) as f:\n",
    "        docs = f.readlines()    \n",
    "    return docs\n",
    "\n",
    "def pre(docs):\n",
    "    porter = stem.porter.PorterStemmer()\n",
    "    docs_prepared=out_path+'docs_prepared.csv'\n",
    "    stop= open ('stopList.txt').read()\n",
    "    stop_list = set(stop.replace(\"\\n\", \" \").split())\n",
    "    docs_cleaned = [[re.sub('[.!,;?()\\W\\d]+', '', word) for word in doc.lower().split()] for doc in docs]\n",
    "    docs_stemed = [[porter.stem(word) for word in document if word not in stoplist] for document in docs_cleaned]\n",
    "    with open(docs_prepared, 'w') as f:\n",
    "        for doc in docs_stemed:f.write(\"%s\\n\" % ' '.join(doc))\n",
    "    return docs_stemed\n",
    "\n",
    "\n",
    "def ls():\n",
    "    index = similarities.MatrixSimilarity(corpus_lsi) \n",
    "    with open(cleanedfile, 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        sims = open('08 LSI - similarities.csv', 'w')\n",
    "        countdegree= open('09 LSI - degreecount.csv', 'w')\n",
    "        sims.write('source,target,weight,type\\n')\n",
    "        for i in range(0,2427):\n",
    "            doc=lines[i]    \n",
    "            vec_bow = dictionary.doc2bow(doc.split())\n",
    "            vec_tran = lsi[tfidf[vec_bow]]\n",
    "            simsinx = index[vec_tran]\n",
    "            count=0;\n",
    "            #for j in range(0,len(simsinx)):\n",
    "                #if simsinx[j]>.5: \n",
    "                    #count=count+1\n",
    "            #countdegree.write(str(i+1)+','+str(count-1));countdegree.write('\\n')\n",
    "            for j in range(i+1,len(simsinx)):\n",
    "                if simsinx[j]>.49:                                        \n",
    "                    sims.write(str(i+1)+','+str(j+1)+','+str(simsinx[j])+',undirected');sims.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1354\n"
     ]
    }
   ],
   "source": [
    "in_path =r'../../data/raw/' # use your path\n",
    "out_path= \"../../data/clean/\"\n",
    "df=concat(in_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1220\n"
     ]
    }
   ],
   "source": [
    "docs=extract_docs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs=pre(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(2021 unique tokens: [u'', u'assimil', u'payoff', u'accur', u'deviat']...)\n",
      "MmCorpus(1220 documents, 2021 features, 72036 non-zero entries)\n"
     ]
    }
   ],
   "source": [
    "## documents_clean = [[word for word in document.split() ] for document in docs]\n",
    "dictionary = corpora.Dictionary(docs)\n",
    "dictionary.filter_extremes(no_below=5)\n",
    "dictionary.compactify() \n",
    "print dictionary\n",
    "\n",
    "class MyCorpus(object):\n",
    "    def __iter__(self):\n",
    "        for doc in docs:\n",
    "            yield dictionary.doc2bow(doc)\n",
    "corpus= MyCorpus() \n",
    "corpora.MmCorpus.serialize('deerwester.mm', corpus)\n",
    "corpus = corpora.MmCorpus('deerwester.mm')\n",
    "print corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = models.tfidfmodel.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=100) \n",
    "corpus_lsi=lsi[corpus_tfidf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    index = similarities.MatrixSimilarity(corpus_lsi) \n",
    "    lines = docs\n",
    "    sims = open('08 LSI - similarities.csv', 'w')\n",
    "    countdegree= open('09 LSI - degreecount.csv', 'w')\n",
    "    sims.write('source,target,weight,type\\n')\n",
    "    for i in range(len(docs)):\n",
    "        doc=lines[i]    \n",
    "        vec_bow = dictionary.doc2bow(doc)\n",
    "        vec_tran = lsi[tfidf[vec_bow]]\n",
    "        simsinx = index[vec_tran]\n",
    "        #count=0;\n",
    "        #for j in range(0,len(simsinx)):\n",
    "            #if simsinx[j]>.5: \n",
    "                #count=count+1\n",
    "        #countdegree.write(str(i+1)+','+str(count-1));countdegree.write('\\n')\n",
    "        for j in range(i+1,len(simsinx)):\n",
    "            if simsinx[j]>.49:                                        \n",
    "                sims.write(str(i+1)+','+str(j+1)+','+str(simsinx[j])+',undirected');sims.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['keyword']=df.DE.apply(lambda x: \"\" if pd.isnull(x) else x.split(';')[0].lower())\n",
    "keywords=df.keyword.groupby(df.keyword).count()\n",
    "keywords.sort_values(ascending=False, inplace=True)\n",
    "keywords.to_csv(out_path+'keywords.csv')\n",
    "len(keywords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
