{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_path =r'../../data/raw/' # use your path\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import glob\n",
    "import re\n",
    "from nltk import stem\n",
    "porter = stem.porter.PorterStemmer()\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "def concat(in_path):\n",
    "    allFiles = glob.glob(in_path + \"/*.txt\")\n",
    "    frame = pd.DataFrame()\n",
    "    list_ = []\n",
    "    for file_ in allFiles:\n",
    "        df_ = pd.read_table(file_,index_col=False, header=0)\n",
    "        list_.append(df_)\n",
    "    df = pd.concat(list_)\n",
    "    df=df[~df.AB.isnull()]\n",
    "    df=df[(df.DT!='Correction') & (df.DT!='Editorial Material')]\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    df.to_csv(out_path+\"articles.csv\")\n",
    "    print len(df)\n",
    "    return df  \n",
    "\n",
    "def extract_docs(df):\n",
    "    docs_csv=out_path+\"docs.csv\"\n",
    "    df.AB.to_csv(docs_csv, index=False)\n",
    "    print len(df)\n",
    "    with open(docs_csv) as f:\n",
    "        docs = f.readlines()    \n",
    "    return docs\n",
    "\n",
    "def pre(docs):\n",
    "    docs_prepared=out_path+'docs_prepared.csv'\n",
    "    stop= open ('stopList.txt').read()\n",
    "    stop_list = set(stop.replace(\"\\n\", \" \").split())\n",
    "    docs_cleaned = [[re.sub('[.!,;?()\\W\\d]+', '', word) for word in doc.lower().split()] for doc in docs]\n",
    "    docs_stemed = [[porter.stem(word) for word in document if word not in stop_list] for document in docs_cleaned]\n",
    "    with open(docs_prepared, 'w') as f:\n",
    "        for doc in docs_stemed:f.write(\"%s\\n\" % ' '.join(doc))\n",
    "    return docs_stemed\n",
    "\n",
    "def sims():\n",
    "    index = similarities.MatrixSimilarity(corpus_lsi) \n",
    "    lines = docs\n",
    "    sims = open('lsi.csv', 'w')\n",
    "    #countdegree= open('09 LSI - degreecount.csv', 'w')\n",
    "    sims.write('source,target,weight,type\\n')\n",
    "    for i in range(len(docs)):\n",
    "        doc=lines[i]    \n",
    "        vec_bow = dictionary.doc2bow(doc)\n",
    "        vec_tran = lsi[tfidf[vec_bow]]\n",
    "        #vec_tran = lda[tfidf[vec_bow]]\n",
    "        simsinx = index[vec_tran]\n",
    "        #count=0;\n",
    "        #for j in range(0,len(simsinx)):\n",
    "            #if simsinx[j]>.5: \n",
    "                #count=count+1\n",
    "        #countdegree.write(str(i+1)+','+str(count-1));countdegree.write('\\n')\n",
    "        for j in range(i+1,len(simsinx)):\n",
    "            if simsinx[j]>.49:                                        \n",
    "                sims.write(str(i)+','+str(j)+','+str(simsinx[j])+',undirected\\n')\n",
    "    sims.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1207\n"
     ]
    }
   ],
   "source": [
    "out_path= \"../../data/clean/\"\n",
    "df=concat(in_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1207\n"
     ]
    }
   ],
   "source": [
    "docs=extract_docs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs=pre(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(2014 unique tokens: [u'', u'assimil', u'payoff', u'accur', u'deviat']...)\n",
      "MmCorpus(1207 documents, 2014 features, 71503 non-zero entries)\n"
     ]
    }
   ],
   "source": [
    "## documents_clean = [[word for word in document.split() ] for document in docs]\n",
    "dictionary = corpora.Dictionary(docs)\n",
    "dictionary.filter_extremes(no_below=5)\n",
    "dictionary.compactify() \n",
    "print dictionary\n",
    "\n",
    "class MyCorpus(object):\n",
    "    def __iter__(self):\n",
    "        for doc in docs:\n",
    "            yield dictionary.doc2bow(doc)\n",
    "corpus= MyCorpus() \n",
    "corpora.MmCorpus.serialize('deerwester.mm', corpus)\n",
    "corpus = corpora.MmCorpus('deerwester.mm')\n",
    "print corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = models.tfidfmodel.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=100) \n",
    "corpus_lsi=lsi[corpus_tfidf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>227</td>\n",
       "      <td>229</td>\n",
       "      <td>0.978077</td>\n",
       "      <td>undirected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2931</th>\n",
       "      <td>298</td>\n",
       "      <td>485</td>\n",
       "      <td>0.962029</td>\n",
       "      <td>undirected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>298</td>\n",
       "      <td>1194</td>\n",
       "      <td>0.967389</td>\n",
       "      <td>undirected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3384</th>\n",
       "      <td>346</td>\n",
       "      <td>974</td>\n",
       "      <td>0.959090</td>\n",
       "      <td>undirected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477</th>\n",
       "      <td>359</td>\n",
       "      <td>485</td>\n",
       "      <td>0.958332</td>\n",
       "      <td>undirected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>359</td>\n",
       "      <td>766</td>\n",
       "      <td>0.969603</td>\n",
       "      <td>undirected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>359</td>\n",
       "      <td>974</td>\n",
       "      <td>0.979315</td>\n",
       "      <td>undirected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3558</th>\n",
       "      <td>368</td>\n",
       "      <td>854</td>\n",
       "      <td>0.957054</td>\n",
       "      <td>undirected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4097</th>\n",
       "      <td>432</td>\n",
       "      <td>658</td>\n",
       "      <td>0.958429</td>\n",
       "      <td>undirected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4490</th>\n",
       "      <td>485</td>\n",
       "      <td>1194</td>\n",
       "      <td>0.958880</td>\n",
       "      <td>undirected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>766</td>\n",
       "      <td>974</td>\n",
       "      <td>0.968490</td>\n",
       "      <td>undirected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>838</td>\n",
       "      <td>1084</td>\n",
       "      <td>0.952247</td>\n",
       "      <td>undirected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6748</th>\n",
       "      <td>943</td>\n",
       "      <td>976</td>\n",
       "      <td>0.958249</td>\n",
       "      <td>undirected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6749</th>\n",
       "      <td>943</td>\n",
       "      <td>1097</td>\n",
       "      <td>0.952605</td>\n",
       "      <td>undirected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6800</th>\n",
       "      <td>963</td>\n",
       "      <td>964</td>\n",
       "      <td>0.953865</td>\n",
       "      <td>undirected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6823</th>\n",
       "      <td>976</td>\n",
       "      <td>1097</td>\n",
       "      <td>0.956832</td>\n",
       "      <td>undirected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source  target    weight        type\n",
       "2259     227     229  0.978077  undirected\n",
       "2931     298     485  0.962029  undirected\n",
       "2941     298    1194  0.967389  undirected\n",
       "3384     346     974  0.959090  undirected\n",
       "3477     359     485  0.958332  undirected\n",
       "3483     359     766  0.969603  undirected\n",
       "3486     359     974  0.979315  undirected\n",
       "3558     368     854  0.957054  undirected\n",
       "4097     432     658  0.958429  undirected\n",
       "4490     485    1194  0.958880  undirected\n",
       "6086     766     974  0.968490  undirected\n",
       "6393     838    1084  0.952247  undirected\n",
       "6748     943     976  0.958249  undirected\n",
       "6749     943    1097  0.952605  undirected\n",
       "6800     963     964  0.953865  undirected\n",
       "6823     976    1097  0.956832  undirected"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('lsi.csv')\n",
    "df[df.weight>.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "905"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['keyword']=df.DE.apply(lambda x: \"\" if pd.isnull(x) else x.split(';')[0].lower())\n",
    "keywords=df.keyword.groupby(df.keyword).count()\n",
    "keywords.sort_values(ascending=False, inplace=True)\n",
    "keywords.to_csv(out_path+'keywords.csv')\n",
    "len(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
